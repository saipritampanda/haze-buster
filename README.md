# ğŸŒ«ï¸ Haze Buster - Lightweight Hybrid CNN for Real-Time Image Dehazing with Perceptual Loss Optimization

A lightweight and robust image dehazing web application powered by a refined hybrid CNN model inspired by AOD-Net.


## Project Overview

**Haze Buster** is an end-to-end AI-based system that removes haze from real-world images using a custom-built deep learning model. The model enhances visibility in hazy images, trained on RESIDE's dataset and deployed via a FastAPI backend for real-time image dehazing.

<a href="https://image-dehaze.vercel.app/" target="_blank">
  <img src="https://img.shields.io/badge/Image%20Dehazing%20Website-Visit-blue?style=for-the-badge&logo=github" alt="Image Dehazing Website"/>
</a>


## ğŸš€ Key Features

- ğŸ”§ **Custom Lightweight CNN Model**: Designed for real-time image dehazing using dynamic input dimensions.
- ğŸ“Š **Refined Architecture**: Combines multi-scale feature extraction, AOD-Net formulation, and refinement blocks.
- ğŸŒ **REST API Backend**: Built using FastAPI and integrated with TensorFlow for serving predictions.
- ğŸ§ª **High Accuracy Metrics**: Achieved excellent **PSNR** and **SSIM** values with optimized loss curves.
- ğŸ“¸ **End-to-End Workflow**: From dataset preprocessing to live inference through web interface.



## Model Architecture

### 1. Full Pipeline Overview

![Implementation Pipeline](Images/Implementation.png)

### 2. Methodology

<p align="center">
  <img src="Images/Methodology.png" alt="Methodology" width="600"/>
</p>

### 2. Detailed CNN Architecture

![Architecture](Images/Architecture.png)

- **Input Layer**: Accepts RGB images of any size `(None, None, 3)`.
- **Multi-Scale Feature Extraction Block**: Series of 1Ã—1, 3Ã—3, 5Ã—5, and 7Ã—7 convolutions.
- **AOD-Net Inspired Formula**: Applies the formula `J(x) = K(x) * I(x) - K(x) + 1` for transmission map estimation.
- **Refinement Block**: 2-layer convolution with batch normalization.
- **Output Layer**: Sigmoid activation for image reconstruction in the 0â€“1 range.



## Training Performance

### 1. Loss (MSE) vs Epoch Graph

<!--
ğŸ” How to URL-encode a path (like for mse graph): Replace space ( ) â†’ %20
-->
<img src="Training%20Files%20and%20Logs/AOD-Net-Modified/History-and-Log-Files/Last%20Model%20and%20Training%20History%20Files%20(2025-05-13%20,%2002-39%20PM)/mse_vs_epoch_graph.png" alt="Loss Curve" width="550">

- **Training Loss**: Steadily decreasing trend, indicating proper learning.
- **Validation Loss**: Shows generalization with acceptable fluctuation.
- **Number of Epochs Trained**: 48

## 2. Evaluation Metrics

- **Loss Function**: Mean Squared Error (MSE)
  ```
         1
  MSE = â”€â”€â”€ * âˆ‘(Yáµ¢ - Å¶áµ¢)Â²
         n

  Where, Yáµ¢ and Å¶áµ¢ denote the ground truth and predicted pixel values respectively, and n is the total number of pixels.
  ```

- **Peak Signal-to-Noise Ratio (PSNR)**: `> 60 dB` on validation set
  ```
                     MAXÂ²
  PSNR = 10 * logâ‚â‚€ â”€â”€â”€â”€â”€â”€
                     MSE
  Where,
  - MAX is the highest possible intensity value a pixel can have in the image
  - Mean Squared Error (MSE) is used both as a standalone loss function and for PSNR calculation.
  ```

- **Structural Similarity Index (SSIM)**: `Around 0.76 - 0.78` (on test samples)
  ```
                     (2 * Î¼â‚“ * Î¼áµ§ + Câ‚) * (2 * Ïƒâ‚“áµ§ + Câ‚‚)   
      SSIM(x, y) =  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
                     (Î¼â‚“Â² + Î¼áµ§Â² + Câ‚) * (Ïƒâ‚“Â² + Ïƒáµ§Â² + Câ‚‚) 

  Where:  
  - Î¼â‚“, Î¼áµ§ = Means of the two images  
  - Ïƒâ‚“Â², Ïƒáµ§Â² = Variances of the two images  
  - Ïƒâ‚“áµ§ = Covariance between the images  
  - Câ‚, Câ‚‚ = Constants for stability
  ```


## ğŸ–¥ï¸ Tech Stack

| Layer         | Technology                   |
|---------------|------------------------------|
| Frontend      | React, Tailwind CSS          |
| Backend API   | FastAPI, Python, TensorFlow  |
| Model         | AOD-Net (Refined Keras)      |
| Deep Learning | TensorFlow + Keras |
| Utilities  | Python, NumPy, Pillow, OpenCV |
| Frontend Deployment   | Vercel              |
| Backend Deployment    | Render               |


## API Endpoint
- **POST** /dehaze
- **Accepts**: .png, .jpg, .jpeg
- **Returns**: Dehazed image in image/png format

## Training Info
- **Dataset**: `RESIDE - ITS` (Indoor Training Set) || `Reside - SOTS` ,  `I-HAZE` & `D-HAZE` are removed for now
- Data Split: `80:10:10`
  - **80%** â†’ Training Set  
  - **10%** â†’ Validation Set  
  - **10%** â†’ Testing Set
- **Training Images per Epoch**: `13,000+`
- **Trainable Parameters**: `1,54,308` (602.77 KB)
- **Training Platform**: `Google Colab` (T4 GPU)
- **Batch Size**: `1` (to preserve image quality)
- **Floating Point Operations (FLOPs)**: `6,727,598,272` (6.7B+ FLOPs or 6727.60 MFLOPs)
  ```
  FLOPs = FLOPs = 2 Ã— Kâ‚• Ã— Kâ‚“ Ã— Cáµ¢â‚™ Ã— Hâ‚’áµ¤â‚œ Ã— Wâ‚’áµ¤â‚œ Ã— Câ‚’áµ¤â‚œ
  ```
- **Dynamic Image Size Support**: Accepts RGB images of any size `(None, None, 3)`.
- **Model saved as**: `aod_net_refined.keras`

## Team Contributions

| Name                                  | Contribution Areas                                          |
|-------------------------------------- | ---------------------------------------------------------- |
| **Sai Pritam Panda** *(Group Leader)* | Data cleaning, preprocessing, model architecture design, training, backend integration |
| **Debi Prasad Mahakud**               | Model implementation, backend setup, error handling        |
| **Prabhat Sharma**                    | Research analysis, debugging, frontend planning            |
| **Hrishikesh Swain**                  | Data collection, frontend prototyping                      |

## ğŸ“ˆ Project Results

- âœ… **Model Performance:**
  - Final Training Loss: **Consistently low MSE**
  - PSNR: **Above 60 dB** on validation set
  - SSIM: **Approximately 0.76 to 0.78**, indicating high structural similarity with ground truth

- ğŸ“Š **Training Insights:**
  - Smooth convergence with minimal overfitting
  - Training graph available: `mse_vs_epoch_graph.png`
  - Detailed training logs available in `training_log.txt`
  
- ğŸ“ **Output Samples:**
  - Real image and dehazed image comparisons
  - Dehazed Images can be downloaded, if viewed in the website
  
- âš¡ **Deployment:**
  - Fast, real-time inference using FastAPI backend
  - Supports dynamic image input sizes for flexible usage

### 1. After AOD-NET Implementation

![](Images/Results/AOD-Net-Modifications/image1.png)

### 2. After AOD-NET Modification

![](Images/Results/Frontend/Comparations/img2.png)

### 3. Website

![](Images/Results/Frontend/image3.png)


## ğŸ“„ License
This project is released under the MIT License.
